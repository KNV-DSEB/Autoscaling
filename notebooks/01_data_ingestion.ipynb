{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Data Ingestion - NASA Web Server Logs\n",
    "\n",
    "## Mục tiêu\n",
    "- Parse raw log files (train.txt, test.txt)\n",
    "- Aggregate thành time series với 3 granularities (1min, 5min, 15min)\n",
    "- Xử lý edge cases và missing data (storm gap)\n",
    "- Lưu processed data dưới dạng parquet\n",
    "\n",
    "## Dữ liệu\n",
    "- **train.txt**: 2,934,960 log entries (01/Jul/1995 → 22/Aug/1995)\n",
    "- **test.txt**: 526,650 log entries (23/Aug/1995 → 31/Aug/1995)\n",
    "\n",
    "## Log Format (Common Log Format)\n",
    "```\n",
    "199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245\n",
    "│              │  │                          │                                │    │\n",
    "│              │  │                          │                                │    └─ Bytes\n",
    "│              │  │                          │                                └─ Status Code\n",
    "│              │  │                          └─ Request\n",
    "│              │  └─ Timestamp + Timezone\n",
    "│              └─ User (luôn \"-\")\n",
    "└─ Host (IP hoặc hostname)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Thêm src vào path để import modules\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from src.data.parser import NASALogParser, quick_parse\n",
    "from src.data.preprocessor import LogPreprocessor, load_timeseries, split_train_test\n",
    "\n",
    "# Config\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Định nghĩa paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_DIR = '../DATA'\n",
    "PROCESSED_DIR = '../data/processed'\n",
    "\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, 'train.txt')\n",
    "TEST_FILE = os.path.join(DATA_DIR, 'test.txt')\n",
    "\n",
    "# Kiểm tra files tồn tại\n",
    "print(f\"Train file: {TRAIN_FILE}\")\n",
    "print(f\"  Exists: {os.path.exists(TRAIN_FILE)}\")\n",
    "if os.path.exists(TRAIN_FILE):\n",
    "    print(f\"  Size: {os.path.getsize(TRAIN_FILE) / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "print(f\"\\nTest file: {TEST_FILE}\")\n",
    "print(f\"  Exists: {os.path.exists(TEST_FILE)}\")\n",
    "if os.path.exists(TEST_FILE):\n",
    "    print(f\"  Size: {os.path.getsize(TEST_FILE) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quick Parse - Kiểm tra format dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse nhanh 100 dòng đầu để kiểm tra format\n",
    "print(\"Kiểm tra format dữ liệu (100 dòng đầu)...\")\n",
    "sample_df = quick_parse(TRAIN_FILE, max_lines=100)\n",
    "\n",
    "print(f\"\\nShape: {sample_df.shape}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(sample_df.dtypes)\n",
    "print(f\"\\nSample data:\")\n",
    "sample_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra các giá trị unique\n",
    "print(\"Phân phối HTTP Methods:\")\n",
    "print(sample_df['method'].value_counts())\n",
    "\n",
    "print(\"\\nPhân phối Status Codes:\")\n",
    "print(sample_df['status_code'].value_counts())\n",
    "\n",
    "print(\"\\nTimezone (tất cả nên là -0400 EDT):\")\n",
    "print(sample_df['timezone'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra bytes field\n",
    "print(\"Bytes statistics:\")\n",
    "print(sample_df['bytes'].describe())\n",
    "\n",
    "print(f\"\\nSố entries có bytes = 0: {(sample_df['bytes'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parse Full Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse toàn bộ training data\n",
    "print(\"=\"*60)\n",
    "print(\"PARSING TRAINING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "parser = NASALogParser()\n",
    "train_df = parser.parse_file(TRAIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thống kê parsing\n",
    "stats = parser.get_stats()\n",
    "print(f\"\\nParsing Statistics:\")\n",
    "print(f\"  Total lines: {stats['total']:,}\")\n",
    "print(f\"  Success: {stats['success']:,} ({stats['success_rate']:.2f}%)\")\n",
    "print(f\"  Failed: {stats['failed']:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra training data\n",
    "print(f\"\\nTraining DataFrame:\")\n",
    "print(f\"  Shape: {train_df.shape}\")\n",
    "print(f\"  Memory usage: {train_df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "print(f\"  Date range: {train_df['timestamp'].min()} to {train_df['timestamp'].max()}\")\n",
    "print(f\"  Duration: {(train_df['timestamp'].max() - train_df['timestamp'].min()).days} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "print(\"\\nSample từ training data:\")\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parse Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse test data\n",
    "print(\"=\"*60)\n",
    "print(\"PARSING TEST DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "parser_test = NASALogParser()\n",
    "test_df = parser_test.parse_file(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra test data\n",
    "print(f\"\\nTest DataFrame:\")\n",
    "print(f\"  Shape: {test_df.shape}\")\n",
    "print(f\"  Date range: {test_df['timestamp'].min()} to {test_df['timestamp'].max()}\")\n",
    "print(f\"  Duration: {(test_df['timestamp'].max() - test_df['timestamp'].min()).days} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combine và Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train và test cho full analysis\n",
    "full_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "full_df = full_df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"Full Dataset:\")\n",
    "print(f\"  Total records: {len(full_df):,}\")\n",
    "print(f\"  Date range: {full_df['timestamp'].min()} to {full_df['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo preprocessor\n",
    "preprocessor = LogPreprocessor(full_df)\n",
    "\n",
    "# Lấy data summary\n",
    "summary = preprocessor.get_data_summary()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal Records: {summary['total_records']:,}\")\n",
    "print(f\"\\nDate Range:\")\n",
    "print(f\"  Start: {summary['date_range']['start']}\")\n",
    "print(f\"  End: {summary['date_range']['end']}\")\n",
    "print(f\"  Duration: {summary['date_range']['duration_days']} days\")\n",
    "\n",
    "print(f\"\\nRequest Status Breakdown:\")\n",
    "for status, count in summary['requests'].items():\n",
    "    if status != 'total':\n",
    "        pct = count / summary['requests']['total'] * 100\n",
    "        print(f\"  {status}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "print(f\"\\nBytes Statistics:\")\n",
    "print(f\"  Total: {summary['bytes']['total'] / 1e9:.2f} GB\")\n",
    "print(f\"  Mean: {summary['bytes']['mean']:,.0f} bytes\")\n",
    "print(f\"  Median: {summary['bytes']['median']:,.0f} bytes\")\n",
    "print(f\"  Max: {summary['bytes']['max']:,} bytes\")\n",
    "\n",
    "print(f\"\\nUnique Hosts (IPs): {summary['unique_hosts']:,}\")\n",
    "\n",
    "print(f\"\\nHTTP Methods:\")\n",
    "for method, count in summary['methods'].items():\n",
    "    print(f\"  {method}: {count:,}\")\n",
    "\n",
    "print(f\"\\nStorm Period (Server Offline):\")\n",
    "print(f\"  Start: {summary['storm_period']['start']}\")\n",
    "print(f\"  End: {summary['storm_period']['end']}\")\n",
    "print(f\"  Duration: {summary['storm_period']['duration_hours']:.1f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detect Gaps trong dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Detect gaps\ngaps = preprocessor.detect_gaps(freq='1min', threshold_minutes=30)\n\nprint(f\"Phát hiện {len(gaps)} gaps > 30 phút:\")\nif len(gaps) > 0:\n    for idx, row in gaps.iterrows():\n        storm_marker = \" [STORM GAP]\" if row['is_storm_gap'] else \"\"\n        print(f\"  {row['gap_start']} → {row['gap_end']} ({row['duration_minutes']:.0f} minutes){storm_marker}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tạo Time Series với nhiều Granularities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo time series với tất cả granularities\n",
    "print(\"=\"*60)\n",
    "print(\"TẠO TIME SERIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "granularities = preprocessor.create_all_granularities(fill_gaps=True)\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "for name, ts in granularities.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Records: {len(ts):,}\")\n",
    "    print(f\"  Date range: {ts.index.min()} to {ts.index.max()}\")\n",
    "    print(f\"  Total requests: {ts['request_count'].sum():,}\")\n",
    "    print(f\"  Avg requests per window: {ts['request_count'].mean():.2f}\")\n",
    "    print(f\"  Max requests per window: {ts['request_count'].max():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem sample của 1-minute data\n",
    "print(\"Sample 1-minute time series:\")\n",
    "granularities['1min'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem các cột có sẵn\n",
    "print(\"Các cột trong time series:\")\n",
    "for col in granularities['1min'].columns:\n",
    "    dtype = granularities['1min'][col].dtype\n",
    "    print(f\"  - {col}: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Traffic Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot hourly traffic\nts_hourly = granularities['1min'].resample('1h').sum()\n\nfig, axes = plt.subplots(2, 1, figsize=(15, 10))\n\n# Requests per hour\nax1 = axes[0]\nax1.plot(ts_hourly.index, ts_hourly['request_count'], linewidth=0.5, alpha=0.8)\nax1.axvspan(preprocessor.STORM_START, preprocessor.STORM_END, alpha=0.3, color='red', label='Storm Gap')\nax1.set_ylabel('Requests per Hour')\nax1.set_title('NASA Web Server Traffic - Requests per Hour')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Bytes per hour\nax2 = axes[1]\nax2.plot(ts_hourly.index, ts_hourly['bytes_total'] / 1e6, linewidth=0.5, alpha=0.8, color='green')\nax2.axvspan(preprocessor.STORM_START, preprocessor.STORM_END, alpha=0.3, color='red', label='Storm Gap')\nax2.set_ylabel('MB per Hour')\nax2.set_xlabel('Time')\nax2.set_title('NASA Web Server Traffic - Bytes per Hour')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('../reports/figures/traffic_overview.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution của requests per minute\n",
    "ts_1min = granularities['1min']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "ax1 = axes[0]\n",
    "ax1.hist(ts_1min['request_count'], bins=100, edgecolor='black', alpha=0.7)\n",
    "ax1.set_xlabel('Requests per Minute')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of Requests per Minute')\n",
    "ax1.axvline(ts_1min['request_count'].mean(), color='red', linestyle='--', label=f\"Mean: {ts_1min['request_count'].mean():.1f}\")\n",
    "ax1.axvline(ts_1min['request_count'].median(), color='green', linestyle='--', label=f\"Median: {ts_1min['request_count'].median():.1f}\")\n",
    "ax1.legend()\n",
    "\n",
    "# Boxplot\n",
    "ax2 = axes[1]\n",
    "ax2.boxplot(ts_1min['request_count'].dropna(), vert=True)\n",
    "ax2.set_ylabel('Requests per Minute')\n",
    "ax2.set_title('Boxplot of Requests per Minute')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/requests_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Lưu Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo thư mục output nếu chưa có\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs('../reports/figures', exist_ok=True)\n",
    "\n",
    "# Lưu processed data\n",
    "print(\"Đang lưu processed data...\")\n",
    "preprocessor.save_processed(PROCESSED_DIR, granularities)\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify saved files\n",
    "print(\"\\nKiểm tra files đã lưu:\")\n",
    "for f in os.listdir(PROCESSED_DIR):\n",
    "    filepath = os.path.join(PROCESSED_DIR, f)\n",
    "    size_mb = os.path.getsize(filepath) / 1024 / 1024\n",
    "    print(f\"  {f}: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading\n",
    "print(\"\\nTest loading từ parquet:\")\n",
    "ts_loaded = load_timeseries(os.path.join(PROCESSED_DIR, 'timeseries_1min.parquet'))\n",
    "print(f\"  Shape: {ts_loaded.shape}\")\n",
    "print(f\"  Index type: {type(ts_loaded.index)}\")\n",
    "print(f\"  Date range: {ts_loaded.index.min()} to {ts_loaded.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test theo đề bài\n",
    "# Train: Jul 1995 + Aug 1-22, 1995\n",
    "# Test: Aug 23-31, 1995\n",
    "\n",
    "ts_1min = granularities['1min']\n",
    "train_ts, test_ts = split_train_test(ts_1min, test_start='1995-08-23')\n",
    "\n",
    "print(\"Train/Test Split:\")\n",
    "print(f\"\\nTrain:\")\n",
    "print(f\"  Date range: {train_ts.index.min()} to {train_ts.index.max()}\")\n",
    "print(f\"  Records: {len(train_ts):,}\")\n",
    "print(f\"  Total requests: {train_ts['request_count'].sum():,}\")\n",
    "\n",
    "print(f\"\\nTest:\")\n",
    "print(f\"  Date range: {test_ts.index.min()} to {test_ts.index.max()}\")\n",
    "print(f\"  Records: {len(test_ts):,}\")\n",
    "print(f\"  Total requests: {test_ts['request_count'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Kết quả Data Ingestion:\n",
    "1. **Parsed thành công** ~3.4 triệu log entries\n",
    "2. **Tạo time series** với 3 granularities (1min, 5min, 15min)\n",
    "3. **Xử lý storm gap** (~38 giờ server offline đầu tháng 8)\n",
    "4. **Lưu** dưới dạng parquet để load nhanh\n",
    "\n",
    "### Files đã tạo:\n",
    "- `data/processed/timeseries_1min.parquet`\n",
    "- `data/processed/timeseries_5min.parquet`\n",
    "- `data/processed/timeseries_15min.parquet`\n",
    "\n",
    "### Next Steps:\n",
    "- Notebook 02: EDA - Phân tích traffic patterns\n",
    "- Notebook 03: Feature Engineering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}