{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 05: LightGBM Modeling\n",
    "\n",
    "## Mục Tiêu\n",
    "- Xây dựng LightGBM model cho traffic forecasting\n",
    "- Time Series Cross-Validation\n",
    "- Feature Importance Analysis\n",
    "- Hyperparameter Tuning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Thêm src vào path\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from src.data.preprocessor import load_timeseries, split_train_test\n",
    "from src.features.feature_engineering import TimeSeriesFeatureEngineer\n",
    "from src.models.lightgbm_forecaster import LightGBMForecaster\n",
    "from src.models.evaluation import calculate_metrics, calculate_forecast_accuracy\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load time series\n",
    "df = load_timeseries('../data/processed/timeseries_15min.parquet')\n",
    "\n",
    "# Remove storm period\n",
    "df_clean = df[df['is_storm_period'] == 0].copy()\n",
    "\n",
    "print(f\"Clean records: {len(df_clean)}\")\n",
    "print(f\"Date range: {df_clean.index.min()} to {df_clean.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "print(\"Creating features...\")\n",
    "fe = TimeSeriesFeatureEngineer(df_clean)\n",
    "df_features = fe.create_all_features(\n",
    "    target_col='request_count',\n",
    "    granularity='15min'\n",
    ")\n",
    "\n",
    "print(f\"Feature DataFrame shape: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature columns\n",
    "feature_cols = fe.get_feature_columns(df_features)\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "\n",
    "# Prepare supervised data\n",
    "X, y = fe.prepare_supervised(\n",
    "    df_features,\n",
    "    target_col='request_count',\n",
    "    feature_cols=feature_cols,\n",
    "    forecast_horizon=1\n",
    ")\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "test_start = '1995-08-23'\n",
    "train_mask = X.index < test_start\n",
    "\n",
    "X_train_full, X_test = X[train_mask], X[~train_mask]\n",
    "y_train_full, y_test = y[train_mask], y[~train_mask]\n",
    "\n",
    "print(f\"Train: {len(X_train_full)} samples\")\n",
    "print(f\"Test: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation set from end of train (20%)\n",
    "val_size = len(X_train_full) // 5\n",
    "X_val = X_train_full.iloc[-val_size:]\n",
    "y_val = y_train_full.iloc[-val_size:]\n",
    "X_train = X_train_full.iloc[:-val_size]\n",
    "y_train = y_train_full.iloc[:-val_size]\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples\")\n",
    "print(f\"Validation: {len(X_val)} samples\")\n",
    "print(f\"Test: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train model\n",
    "model = LightGBMForecaster(\n",
    "    n_estimators=1000,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "print(\"Training LightGBM model...\")\n",
    "model.fit(X_train, y_train, X_val, y_val, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training info\n",
    "print(f\"\\nBest iteration: {model.best_iteration}\")\n",
    "print(f\"Best validation score: {model.model.best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 features\n",
    "fi = model.get_feature_importance(20)\n",
    "print(\"Top 20 Most Important Features:\")\n",
    "print(\"=\"*50)\n",
    "print(fi.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "fi_plot = model.get_feature_importance(20)\n",
    "bars = ax.barh(range(len(fi_plot)), fi_plot['importance'], align='center', color='steelblue')\n",
    "ax.set_yticks(range(len(fi_plot)))\n",
    "ax.set_yticklabels(fi_plot['feature'])\n",
    "ax.set_xlabel('Importance (Gain)')\n",
    "ax.set_title('Top 20 Feature Importances - LightGBM')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/lightgbm_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time Series Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation với full training data\n",
    "print(\"Running Time Series Cross-Validation...\")\n",
    "cv_results = model.cross_validate(\n",
    "    X_train_full, y_train_full,\n",
    "    n_splits=5,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV Summary\n",
    "print(\"\\nCross-Validation Summary:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"  RMSE: {cv_results['rmse_mean']:.4f} (+/- {cv_results['rmse_std']:.4f})\")\n",
    "print(f\"  MAE:  {cv_results['mae_mean']:.4f} (+/- {cv_results['mae_std']:.4f})\")\n",
    "print(f\"  MAPE: {cv_results['mape_mean']:.2f}% (+/- {cv_results['mape_std']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on full training data\n",
    "print(\"Retraining on full training data...\")\n",
    "\n",
    "final_model = LightGBMForecaster(\n",
    "    n_estimators=model.best_iteration,  # Use best iteration from CV\n",
    "    early_stopping_rounds=None  # No early stopping for final model\n",
    ")\n",
    "\n",
    "# Use last portion as validation for monitoring\n",
    "val_size_final = len(X_train_full) // 10\n",
    "final_model.fit(\n",
    "    X_train_full.iloc[:-val_size_final], \n",
    "    y_train_full.iloc[:-val_size_final],\n",
    "    X_train_full.iloc[-val_size_final:],\n",
    "    y_train_full.iloc[-val_size_final:],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test predictions\n",
    "predictions = final_model.predict(X_test)\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Min prediction: {predictions.min():.2f}\")\n",
    "print(f\"Max prediction: {predictions.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(y_test.index, y_test.values, label='Actual', alpha=0.8)\n",
    "ax.plot(y_test.index, predictions, label='LightGBM Forecast', alpha=0.8, linestyle='--')\n",
    "\n",
    "ax.set_xlabel('Timestamp')\n",
    "ax.set_ylabel('Request Count')\n",
    "ax.set_title('LightGBM Forecast vs Actual (Test Set)')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/lightgbm_forecast.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "metrics = calculate_metrics(y_test.values, predictions)\n",
    "\n",
    "print(\"\\nLightGBM Model Metrics:\")\n",
    "print(\"=\"*50)\n",
    "for name, value in metrics.items():\n",
    "    print(f\"  {name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast accuracy\n",
    "accuracy = calculate_forecast_accuracy(y_test.values, predictions, threshold_pct=20)\n",
    "\n",
    "print(\"\\nForecast Accuracy Analysis:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"  Accuracy within 20%: {accuracy['accuracy_within_threshold']:.2f}%\")\n",
    "print(f\"  Mean Error: {accuracy['mean_error']:.2f}\")\n",
    "print(f\"  Mean % Error: {accuracy['mean_pct_error']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis\n",
    "errors = predictions - y_test.values\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Error histogram\n",
    "axes[0].hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(x=0, color='red', linestyle='--')\n",
    "axes[0].set_title('Error Distribution')\n",
    "axes[0].set_xlabel('Error')\n",
    "\n",
    "# Actual vs Predicted\n",
    "axes[1].scatter(y_test.values, predictions, alpha=0.5, s=10)\n",
    "max_val = max(y_test.values.max(), predictions.max())\n",
    "axes[1].plot([0, max_val], [0, max_val], 'r--')\n",
    "axes[1].set_xlabel('Actual')\n",
    "axes[1].set_ylabel('Predicted')\n",
    "axes[1].set_title('Predicted vs Actual')\n",
    "\n",
    "# Error over time\n",
    "axes[2].plot(y_test.index, errors, alpha=0.7)\n",
    "axes[2].axhline(y=0, color='red', linestyle='--')\n",
    "axes[2].set_title('Error over Time')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/lightgbm_error_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Tuning (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple grid search\n",
    "param_grid = {\n",
    "    'num_leaves': [15, 31, 50],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "best_params = None\n",
    "best_rmse = float('inf')\n",
    "results = []\n",
    "\n",
    "print(\"Running hyperparameter search...\")\n",
    "for num_leaves in param_grid['num_leaves']:\n",
    "    for lr in param_grid['learning_rate']:\n",
    "        params = {\n",
    "            'num_leaves': num_leaves,\n",
    "            'learning_rate': lr\n",
    "        }\n",
    "        \n",
    "        temp_model = LightGBMForecaster(\n",
    "            params=params,\n",
    "            n_estimators=500,\n",
    "            early_stopping_rounds=30\n",
    "        )\n",
    "        temp_model.fit(X_train, y_train, X_val, y_val, verbose=0)\n",
    "        \n",
    "        preds = temp_model.predict(X_val)\n",
    "        rmse = np.sqrt(np.mean((y_val.values - preds) ** 2))\n",
    "        \n",
    "        results.append({\n",
    "            'num_leaves': num_leaves,\n",
    "            'learning_rate': lr,\n",
    "            'rmse': rmse\n",
    "        })\n",
    "        \n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_params = params.copy()\n",
    "        \n",
    "        print(f\"  num_leaves={num_leaves}, lr={lr}: RMSE={rmse:.4f}\")\n",
    "\n",
    "print(f\"\\nBest params: {best_params}\")\n",
    "print(f\"Best RMSE: {best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results heatmap\n",
    "results_df = pd.DataFrame(results)\n",
    "pivot = results_df.pivot(index='num_leaves', columns='learning_rate', values='rmse')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(pivot, annot=True, fmt='.2f', cmap='RdYlGn_r')\n",
    "plt.title('Hyperparameter Search Results (RMSE)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/lightgbm_hyperparam.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "final_model.save('../models/lightgbm_15min.pkl')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading\n",
    "loaded_model = LightGBMForecaster.load('../models/lightgbm_15min.pkl')\n",
    "print(f\"Model loaded with {len(loaded_model.feature_names)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"            LIGHTGBM MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel: LightGBM Gradient Boosting\")\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Granularity: 15 minutes\")\n",
    "print(f\"\\nTraining Data:\")\n",
    "print(f\"  Train: {len(X_train)} samples\")\n",
    "print(f\"  Validation: {len(X_val)} samples\")\n",
    "print(f\"\\nTest Data: {len(X_test)} samples\")\n",
    "print(f\"\\nCross-Validation (5-fold):\")\n",
    "print(f\"  RMSE: {cv_results['rmse_mean']:.2f} (+/- {cv_results['rmse_std']:.2f})\")\n",
    "print(f\"  MAE:  {cv_results['mae_mean']:.2f} (+/- {cv_results['mae_std']:.2f})\")\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  RMSE: {metrics['RMSE']:.2f} requests/interval\")\n",
    "print(f\"  MAE: {metrics['MAE']:.2f} requests/interval\")\n",
    "print(f\"  MAPE: {metrics['MAPE']:.2f}%\")\n",
    "print(f\"\\nTop 5 Features:\")\n",
    "for i, row in fi.head(5).iterrows():\n",
    "    print(f\"  {row['feature']}: {row['importance']:.2f}\")\n",
    "print(f\"\\nSaved to: ../models/lightgbm_15min.pkl\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
