{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 08: Anomaly Detection (Bonus)\n",
    "\n",
    "## Mục Tiêu\n",
    "- Phát hiện traffic anomalies (spikes, drops)\n",
    "- Phân biệt DDoS patterns\n",
    "- Kết hợp với autoscaling policy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Thêm src vào path\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from src.data.preprocessor import load_timeseries\n",
    "from src.anomaly.detector import AnomalyDetector\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load time series\n",
    "df = load_timeseries('../data/processed/timeseries_15min.parquet')\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use request_count as main metric\n",
    "traffic = df['request_count'].copy()\n",
    "\n",
    "print(f\"Traffic statistics:\")\n",
    "print(traffic.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Anomaly Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detector\n",
    "detector = AnomalyDetector()\n",
    "\n",
    "print(\"Anomaly Detector initialized\")\n",
    "print(\"Available methods:\")\n",
    "print(\"  - Z-score: Statistical deviation detection\")\n",
    "print(\"  - IQR: Interquartile range based detection\")\n",
    "print(\"  - Isolation Forest: ML-based outlier detection\")\n",
    "print(\"  - Rolling: Comparison with rolling statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Z-Score Based Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score detection\n",
    "zscore_anomalies = detector.detect_zscore(traffic, threshold=3.0)\n",
    "\n",
    "print(f\"Z-Score Anomalies (threshold=3.0):\")\n",
    "print(f\"  Total anomalies: {zscore_anomalies.sum()}\")\n",
    "print(f\"  Percentage: {zscore_anomalies.sum()/len(traffic)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Z-score anomalies\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(traffic.index, traffic.values, label='Traffic', alpha=0.7)\n",
    "ax.scatter(traffic.index[zscore_anomalies], traffic[zscore_anomalies], \n",
    "           color='red', s=50, label='Anomaly', zorder=5)\n",
    "\n",
    "# Add thresholds\n",
    "mean = traffic.mean()\n",
    "std = traffic.std()\n",
    "ax.axhline(y=mean + 3*std, color='red', linestyle='--', alpha=0.5, label='Upper Threshold')\n",
    "ax.axhline(y=mean - 3*std, color='red', linestyle='--', alpha=0.5, label='Lower Threshold')\n",
    "\n",
    "ax.set_xlabel('Timestamp')\n",
    "ax.set_ylabel('Request Count')\n",
    "ax.set_title('Z-Score Anomaly Detection')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/anomaly_zscore.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. IQR Based Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR detection\n",
    "iqr_anomalies = detector.detect_iqr(traffic, k=1.5)\n",
    "\n",
    "print(f\"IQR Anomalies (k=1.5):\")\n",
    "print(f\"  Total anomalies: {iqr_anomalies.sum()}\")\n",
    "print(f\"  Percentage: {iqr_anomalies.sum()/len(traffic)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize with boxplot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Boxplot\n",
    "axes[0].boxplot(traffic.dropna())\n",
    "axes[0].set_title('Traffic Distribution (Boxplot)')\n",
    "axes[0].set_ylabel('Request Count')\n",
    "\n",
    "# Time series with IQR anomalies\n",
    "axes[1].plot(traffic.index, traffic.values, label='Traffic', alpha=0.7)\n",
    "axes[1].scatter(traffic.index[iqr_anomalies], traffic[iqr_anomalies], \n",
    "                color='orange', s=50, label='Anomaly', zorder=5)\n",
    "axes[1].set_xlabel('Timestamp')\n",
    "axes[1].set_ylabel('Request Count')\n",
    "axes[1].set_title('IQR Anomaly Detection')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/anomaly_iqr.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Rolling Window Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling window detection (compare with local statistics)\n",
    "rolling_anomalies = detector.detect_rolling(traffic, window=96, threshold=2.5)  # 24-hour window\n",
    "\n",
    "print(f\"Rolling Window Anomalies:\")\n",
    "print(f\"  Total anomalies: {rolling_anomalies.sum()}\")\n",
    "print(f\"  Percentage: {rolling_anomalies.sum()/len(traffic)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize rolling detection\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Calculate rolling stats for visualization\n",
    "rolling_mean = traffic.rolling(96).mean()\n",
    "rolling_std = traffic.rolling(96).std()\n",
    "\n",
    "ax.plot(traffic.index, traffic.values, label='Traffic', alpha=0.7)\n",
    "ax.plot(rolling_mean.index, rolling_mean.values, label='Rolling Mean (24h)', \n",
    "        color='green', linestyle='--')\n",
    "ax.fill_between(rolling_mean.index, \n",
    "                rolling_mean - 2.5*rolling_std, \n",
    "                rolling_mean + 2.5*rolling_std,\n",
    "                alpha=0.2, color='green', label='Normal Range')\n",
    "\n",
    "ax.scatter(traffic.index[rolling_anomalies], traffic[rolling_anomalies], \n",
    "           color='red', s=50, label='Anomaly', zorder=5)\n",
    "\n",
    "ax.set_xlabel('Timestamp')\n",
    "ax.set_ylabel('Request Count')\n",
    "ax.set_title('Rolling Window Anomaly Detection')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/anomaly_rolling.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Isolation Forest Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation Forest (ML-based)\n",
    "# Create features for isolation forest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Create feature matrix\n",
    "features = pd.DataFrame({\n",
    "    'request_count': traffic,\n",
    "    'hour': traffic.index.hour,\n",
    "    'day_of_week': traffic.index.dayofweek,\n",
    "    'lag_1': traffic.shift(1),\n",
    "    'lag_4': traffic.shift(4),  # 1-hour lag\n",
    "    'rolling_mean_4': traffic.rolling(4).mean(),\n",
    "    'diff': traffic.diff()\n",
    "}).dropna()\n",
    "\n",
    "# Train Isolation Forest\n",
    "iso_forest = IsolationForest(\n",
    "    contamination=0.05,  # Expect 5% anomalies\n",
    "    random_state=42,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "iso_predictions = iso_forest.fit_predict(features)\n",
    "iso_anomalies = pd.Series(iso_predictions == -1, index=features.index)\n",
    "\n",
    "print(f\"Isolation Forest Anomalies:\")\n",
    "print(f\"  Total anomalies: {iso_anomalies.sum()}\")\n",
    "print(f\"  Percentage: {iso_anomalies.sum()/len(features)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Isolation Forest results\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(traffic.index, traffic.values, label='Traffic', alpha=0.7)\n",
    "ax.scatter(features.index[iso_anomalies], traffic.loc[features.index[iso_anomalies]], \n",
    "           color='purple', s=50, label='Anomaly', zorder=5)\n",
    "\n",
    "ax.set_xlabel('Timestamp')\n",
    "ax.set_ylabel('Request Count')\n",
    "ax.set_title('Isolation Forest Anomaly Detection')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/anomaly_isolation_forest.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Spike Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect sudden spikes\n",
    "spikes = detector.detect_spikes(traffic, window=4, threshold=2.0)\n",
    "\n",
    "print(f\"Spike Detection:\")\n",
    "print(f\"  Total spikes: {spikes.sum()}\")\n",
    "print(f\"  Percentage: {spikes.sum()/len(traffic)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze spike patterns\n",
    "spike_times = traffic.index[spikes]\n",
    "spike_values = traffic[spikes]\n",
    "\n",
    "print(\"\\nTop 10 Largest Spikes:\")\n",
    "top_spikes = spike_values.nlargest(10)\n",
    "for timestamp, value in top_spikes.items():\n",
    "    print(f\"  {timestamp}: {value:.0f} requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize spikes\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(traffic.index, traffic.values, label='Traffic', alpha=0.7)\n",
    "ax.scatter(traffic.index[spikes], traffic[spikes], \n",
    "           color='red', s=80, marker='^', label='Spike', zorder=5)\n",
    "\n",
    "ax.set_xlabel('Timestamp')\n",
    "ax.set_ylabel('Request Count')\n",
    "ax.set_title('Traffic Spike Detection')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/anomaly_spikes.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. DDoS-like Pattern Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDoS pattern: High traffic + Low unique hosts ratio\n",
    "# (Many requests from few sources)\n",
    "\n",
    "if 'unique_hosts' in df.columns:\n",
    "    ddos_suspicious = detector.detect_ddos_pattern(\n",
    "        traffic, \n",
    "        df['unique_hosts'],\n",
    "        traffic_threshold=2.0,\n",
    "        host_ratio_threshold=0.5\n",
    "    )\n",
    "    \n",
    "    print(f\"DDoS-like Pattern Detection:\")\n",
    "    print(f\"  Suspicious events: {ddos_suspicious.sum()}\")\n",
    "    print(f\"  Percentage: {ddos_suspicious.sum()/len(traffic)*100:.2f}%\")\n",
    "else:\n",
    "    print(\"unique_hosts column not available for DDoS analysis\")\n",
    "    ddos_suspicious = pd.Series(False, index=traffic.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Storm Period Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the storm period (server outage)\n",
    "storm_mask = df['is_storm_period'] == 1\n",
    "storm_periods = df[storm_mask]\n",
    "\n",
    "print(f\"Storm Period Analysis:\")\n",
    "print(f\"  Storm records: {len(storm_periods)}\")\n",
    "print(f\"  Start: {storm_periods.index.min() if len(storm_periods) > 0 else 'N/A'}\")\n",
    "print(f\"  End: {storm_periods.index.max() if len(storm_periods) > 0 else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize storm period\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(traffic.index, traffic.values, label='Traffic', alpha=0.7)\n",
    "\n",
    "# Highlight storm period\n",
    "if len(storm_periods) > 0:\n",
    "    storm_start = storm_periods.index.min()\n",
    "    storm_end = storm_periods.index.max()\n",
    "    ax.axvspan(storm_start, storm_end, alpha=0.3, color='red', label='Storm Period')\n",
    "\n",
    "ax.set_xlabel('Timestamp')\n",
    "ax.set_ylabel('Request Count')\n",
    "ax.set_title('Traffic with Storm Period Highlighted')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/anomaly_storm.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Combined Anomaly Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine multiple detection methods\n",
    "combined_score = detector.get_combined_anomaly_score(\n",
    "    traffic,\n",
    "    methods=['zscore', 'iqr', 'rolling', 'spike']\n",
    ")\n",
    "\n",
    "print(f\"Combined Anomaly Score Distribution:\")\n",
    "print(combined_score.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize combined score\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Traffic\n",
    "axes[0].plot(traffic.index, traffic.values, alpha=0.7)\n",
    "axes[0].set_ylabel('Request Count')\n",
    "axes[0].set_title('Traffic')\n",
    "\n",
    "# Combined anomaly score\n",
    "axes[1].plot(combined_score.index, combined_score.values, color='red', alpha=0.7)\n",
    "axes[1].axhline(y=2, color='orange', linestyle='--', label='Moderate Threshold')\n",
    "axes[1].axhline(y=3, color='red', linestyle='--', label='Severe Threshold')\n",
    "axes[1].fill_between(combined_score.index, 0, combined_score.values, alpha=0.3, color='red')\n",
    "axes[1].set_ylabel('Anomaly Score')\n",
    "axes[1].set_xlabel('Timestamp')\n",
    "axes[1].set_title('Combined Anomaly Score')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/anomaly_combined_score.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Anomaly Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate anomaly report\n",
    "report = detector.generate_report(traffic)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"               ANOMALY DETECTION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nData Period: {traffic.index.min()} to {traffic.index.max()}\")\n",
    "print(f\"Total Records: {len(traffic)}\")\n",
    "print(f\"\\n\" + \"-\"*70)\n",
    "print(\"DETECTION RESULTS:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Method':<25} {'Anomalies':<15} {'Percentage':<15}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Z-Score (3σ)':<25} {zscore_anomalies.sum():<15} {zscore_anomalies.sum()/len(traffic)*100:.2f}%\")\n",
    "print(f\"{'IQR (1.5x)':<25} {iqr_anomalies.sum():<15} {iqr_anomalies.sum()/len(traffic)*100:.2f}%\")\n",
    "print(f\"{'Rolling Window':<25} {rolling_anomalies.sum():<15} {rolling_anomalies.sum()/len(traffic)*100:.2f}%\")\n",
    "print(f\"{'Isolation Forest':<25} {iso_anomalies.sum():<15} {iso_anomalies.sum()/len(features)*100:.2f}%\")\n",
    "print(f\"{'Spike Detection':<25} {spikes.sum():<15} {spikes.sum()/len(traffic)*100:.2f}%\")\n",
    "print(\"-\"*70)\n",
    "print(f\"\\nKEY FINDINGS:\")\n",
    "print(f\"  - Storm period detected: {storm_mask.sum()} records\")\n",
    "print(f\"  - Major traffic spikes: {spikes.sum()}\")\n",
    "severe_anomalies = (combined_score >= 3).sum()\n",
    "print(f\"  - Severe anomalies (score >= 3): {severe_anomalies}\")\n",
    "print(f\"\\nRECOMMENDATIONS:\")\n",
    "print(f\"  - Use combined anomaly score for autoscaling decisions\")\n",
    "print(f\"  - Set alerts for score > 3 (severe anomalies)\")\n",
    "print(f\"  - Investigate DDoS patterns during high-traffic spikes\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
