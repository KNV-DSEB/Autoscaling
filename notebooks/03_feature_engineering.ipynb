{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03: Feature Engineering\n",
    "\n",
    "## Mục Tiêu\n",
    "- Tạo features từ time series data cho forecasting models\n",
    "- Temporal features (hour, day_of_week, cyclical encoding)\n",
    "- Lag features và rolling statistics\n",
    "- Chuẩn bị data cho supervised learning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Thêm src vào path\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from src.features.feature_engineering import TimeSeriesFeatureEngineer\n",
    "from src.data.preprocessor import load_timeseries, split_train_test\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load time series data (15-minute granularity)\n",
    "df_15min = load_timeseries('../data/processed/timeseries_15min.parquet')\n",
    "\n",
    "print(f\"Data shape: {df_15min.shape}\")\n",
    "print(f\"Date range: {df_15min.index.min()} to {df_15min.index.max()}\")\n",
    "print(f\"\\nColumns: {df_15min.columns.tolist()}\")\n",
    "df_15min.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loại bỏ storm period cho training\n",
    "df_clean = df_15min[df_15min['is_storm_period'] == 0].copy()\n",
    "print(f\"Clean data: {len(df_clean)} records (removed {len(df_15min) - len(df_clean)} storm records)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering với TimeSeriesFeatureEngineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo Feature Engineer\n",
    "fe = TimeSeriesFeatureEngineer(df_clean)\n",
    "\n",
    "# Tạo tất cả features\n",
    "df_features = fe.create_all_features(\n",
    "    target_col='request_count',\n",
    "    granularity='15min'\n",
    ")\n",
    "\n",
    "print(f\"Feature DataFrame shape: {df_features.shape}\")\n",
    "print(f\"\\nNumber of features created: {len(df_features.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem tất cả features\n",
    "print(\"All features:\")\n",
    "for i, col in enumerate(df_features.columns):\n",
    "    print(f\"  {i+1}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chi Tiết Các Loại Features\n",
    "\n",
    "### 3.1 Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal features\n",
    "temporal_cols = ['hour', 'day_of_week', 'day_of_month', 'is_weekend', 'is_business_hour',\n",
    "                 'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos']\n",
    "\n",
    "print(\"Temporal Features:\")\n",
    "df_features[temporal_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cyclical encoding\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Hour cyclical\n",
    "sample = df_features[['hour', 'hour_sin', 'hour_cos']].drop_duplicates().sort_values('hour')\n",
    "axes[0].scatter(sample['hour_cos'], sample['hour_sin'], c=sample['hour'], cmap='viridis', s=100)\n",
    "axes[0].set_xlabel('hour_cos')\n",
    "axes[0].set_ylabel('hour_sin')\n",
    "axes[0].set_title('Hour Cyclical Encoding')\n",
    "for _, row in sample.iterrows():\n",
    "    axes[0].annotate(f\"{int(row['hour'])}h\", (row['hour_cos'], row['hour_sin']), fontsize=8)\n",
    "\n",
    "# Day of week cyclical\n",
    "sample_dow = df_features[['day_of_week', 'dow_sin', 'dow_cos']].drop_duplicates().sort_values('day_of_week')\n",
    "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[1].scatter(sample_dow['dow_cos'], sample_dow['dow_sin'], c=sample_dow['day_of_week'], cmap='viridis', s=100)\n",
    "axes[1].set_xlabel('dow_cos')\n",
    "axes[1].set_ylabel('dow_sin')\n",
    "axes[1].set_title('Day of Week Cyclical Encoding')\n",
    "for _, row in sample_dow.iterrows():\n",
    "    axes[1].annotate(days[int(row['day_of_week'])], (row['dow_cos'], row['dow_sin']), fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/cyclical_encoding.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Lag features\nlag_cols = [col for col in df_features.columns if '_lag_' in col]\nprint(f\"Lag features ({len(lag_cols)}): {lag_cols}\")\n\n# Sample data\ndf_features[['request_count'] + lag_cols].head(10)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Correlation của lag features với target\nif len(lag_cols) > 0:\n    lag_corr = df_features[['request_count'] + lag_cols].corr()['request_count'].drop('request_count')\n    \n    plt.figure(figsize=(10, 5))\n    lag_corr.plot(kind='bar', color='steelblue')\n    plt.title('Correlation của Lag Features với Request Count')\n    plt.xlabel('Lag Feature')\n    plt.ylabel('Correlation')\n    plt.xticks(rotation=45)\n    plt.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n    plt.tight_layout()\n    plt.savefig('../reports/figures/lag_correlation.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    print(\"\\nLag Correlations:\")\n    print(lag_corr.sort_values(ascending=False))\nelse:\n    print(\"No lag features found!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Rolling Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Rolling features\nrolling_cols = [col for col in df_features.columns if '_rolling_' in col]\nprint(f\"Rolling features ({len(rolling_cols)}): {rolling_cols}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize rolling statistics\nsample_data = df_features.iloc[200:400].copy()\n\nfig, ax = plt.subplots(figsize=(14, 6))\n\nax.plot(sample_data.index, sample_data['request_count'], label='Actual', alpha=0.8)\n\n# Rolling means - check with correct column names\nrolling_mean_cols = [col for col in sample_data.columns if '_rolling_mean_' in col]\nif len(rolling_mean_cols) >= 1:\n    ax.plot(sample_data.index, sample_data[rolling_mean_cols[0]], label=f'{rolling_mean_cols[0]}', alpha=0.7)\nif len(rolling_mean_cols) >= 2:\n    ax.plot(sample_data.index, sample_data[rolling_mean_cols[-1]], label=f'{rolling_mean_cols[-1]}', alpha=0.7)\n\nax.set_xlabel('Timestamp')\nax.set_ylabel('Request Count')\nax.set_title('Request Count với Rolling Means')\nax.legend()\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.savefig('../reports/figures/rolling_features.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Derived Features (Diff, Pct Change, EWM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Derived features\nderived_cols = [col for col in df_features.columns if '_diff_' in col or '_pct_change_' in col or '_ewm_' in col]\nprint(f\"Derived features ({len(derived_cols)}): {derived_cols}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Distribution của diff features\ndiff_col = [col for col in df_features.columns if '_diff_1' in col]\npct_col = [col for col in df_features.columns if '_pct_change_1' in col]\n\nif len(diff_col) > 0:\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Diff distribution\n    axes[0].hist(df_features[diff_col[0]].dropna(), bins=50, edgecolor='black', alpha=0.7)\n    axes[0].axvline(x=0, color='red', linestyle='--')\n    axes[0].set_title(f'Distribution của {diff_col[0]}')\n    axes[0].set_xlabel('Change')\n    axes[0].set_ylabel('Frequency')\n    \n    # Pct change distribution\n    if len(pct_col) > 0:\n        pct_data = df_features[pct_col[0]].dropna()\n        pct_data = pct_data[(pct_data > -2) & (pct_data < 2)]  # Filter outliers\n        axes[1].hist(pct_data, bins=50, edgecolor='black', alpha=0.7)\n        axes[1].axvline(x=0, color='red', linestyle='--')\n        axes[1].set_title(f'Distribution của {pct_col[0]}')\n        axes[1].set_xlabel('% Change')\n        axes[1].set_ylabel('Frequency')\n    \n    plt.tight_layout()\n    plt.savefig('../reports/figures/derived_features.png', dpi=150, bbox_inches='tight')\n    plt.show()\nelse:\n    print(\"No diff features found!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy danh sách feature columns\n",
    "feature_cols = fe.get_feature_columns(df_features)\n",
    "print(f\"Total feature columns: {len(feature_cols)}\")\n",
    "print(f\"\\nFeatures: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix cho top features\n",
    "# Chọn features có correlation cao với target\n",
    "corr_with_target = df_features[feature_cols + ['request_count']].corr()['request_count'].drop('request_count')\n",
    "top_features = corr_with_target.abs().nlargest(15).index.tolist()\n",
    "\n",
    "# Correlation heatmap\n",
    "corr_matrix = df_features[top_features + ['request_count']].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, fmt='.2f')\n",
    "plt.title('Correlation Matrix - Top 15 Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/feature_correlation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top features by correlation\n",
    "print(\"Top 20 Features by Correlation với Target:\")\n",
    "print(\"=\"*50)\n",
    "for i, (feat, corr) in enumerate(corr_with_target.abs().nlargest(20).items()):\n",
    "    actual_corr = corr_with_target[feat]\n",
    "    print(f\"{i+1:2d}. {feat:30s}: {actual_corr:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Supervised Learning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn bị data cho supervised learning\n",
    "X, y = fe.prepare_supervised(\n",
    "    df_features,\n",
    "    target_col='request_count',\n",
    "    feature_cols=feature_cols,\n",
    "    forecast_horizon=1  # Dự đoán 1 step ahead\n",
    ")\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nFirst few rows of X:\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "test_start = '1995-08-23'\n",
    "train_mask = X.index < test_start\n",
    "\n",
    "X_train, X_test = X[train_mask], X[~train_mask]\n",
    "y_train, y_test = y[train_mask], y[~train_mask]\n",
    "\n",
    "print(f\"Train set: {len(X_train)} samples ({X_train.index.min()} to {X_train.index.max()})\")\n",
    "print(f\"Test set: {len(X_test)} samples ({X_test.index.min()} to {X_test.index.max()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = X.isnull().sum()\n",
    "missing_cols = missing[missing > 0]\n",
    "\n",
    "if len(missing_cols) > 0:\n",
    "    print(\"Columns with missing values:\")\n",
    "    print(missing_cols)\n",
    "else:\n",
    "    print(\"No missing values in feature columns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature-engineered data\n",
    "df_features.to_parquet('../data/processed/features_15min.parquet')\n",
    "print(\"Saved: features_15min.parquet\")\n",
    "\n",
    "# Save train/test splits\n",
    "X_train.to_parquet('../data/processed/X_train_15min.parquet')\n",
    "X_test.to_parquet('../data/processed/X_test_15min.parquet')\n",
    "y_train.to_frame().to_parquet('../data/processed/y_train_15min.parquet')\n",
    "y_test.to_frame().to_parquet('../data/processed/y_test_15min.parquet')\n",
    "\n",
    "print(\"\\nTrain/Test data saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"            FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nGranularity: 15 minutes\")\n",
    "print(f\"Total records: {len(df_features)}\")\n",
    "print(f\"\\nFeatures created: {len(feature_cols)}\")\n",
    "print(f\"  - Temporal: hour, day_of_week, is_weekend, cyclical encoding\")\n",
    "print(f\"  - Lag: {[c for c in feature_cols if c.startswith('lag_')]}\")\n",
    "print(f\"  - Rolling: mean, std, max, min\")\n",
    "print(f\"  - Derived: diff, pct_change, ewm\")\n",
    "print(f\"\\nTrain samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"\\nTop 5 Features by Correlation:\")\n",
    "for feat, corr in corr_with_target.abs().nlargest(5).items():\n",
    "    print(f\"  - {feat}: {corr_with_target[feat]:+.4f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}